{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from entity_retrieval import surface_index_memory\n",
    "from itertools import product\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ujson\n",
    "import re\n",
    "import requests\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nor_to_sexpr import convert_s_expression_to_sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\TOPU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:entity_retrieval.surface_index_memory:Loading entity vocabulary from disk.\n",
      "INFO:entity_retrieval.surface_index_memory:Loading surfaces from disk.\n",
      "INFO:entity_retrieval.surface_index_memory:Done initializing surface index.\n"
     ]
    }
   ],
   "source": [
    "surface_index = surface_index_memory.EntitySurfaceIndexMemory(\n",
    "    \"vi_entity_list_file_wikidata_complete_all_mention\", \"vi_entity_surface_map_file_wikidata_complete_all_mention\",\"vi_wiki_complete_all_mention\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_expression(expr):\n",
    "    \"\"\"Kiểm tra tính hợp lệ của biểu thức bằng cách đếm số ngoặc mở và đóng.\"\"\"\n",
    "    count = 0\n",
    "    for char in expr:\n",
    "        if char == '(':\n",
    "            count += 1\n",
    "        elif char == ')':\n",
    "            count -= 1\n",
    "        if count < 0:\n",
    "            return False  # Gặp ngoặc đóng trước ngoặc mở\n",
    "    return count == 0\n",
    "\n",
    "def fix_unbalanced_parentheses(expr):\n",
    "    \"\"\"Loại bỏ ngoặc đóng dư nếu có.\"\"\"\n",
    "    while not is_valid_expression(expr) and expr.endswith(')'):\n",
    "        expr = expr[:-1]\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TOPU\\anaconda3\\envs\\py38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Trích xuất vector embedding từ mô hình\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Mean pooling\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "def find_entity_or_relation(label, label_map, facc1_index, top_k=50, similarity_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Tìm thực thể hoặc quan hệ từ gold maps, SimCSE hoặc FACC1.\n",
    "    \"\"\"\n",
    "    label_lower = label.lower()\n",
    "\n",
    "    # Nếu có trong label_map, trả về ngay\n",
    "    if label_map and label_lower in label_map:\n",
    "        return label_map[label_lower]\n",
    "\n",
    "    # Lấy embedding cho label\n",
    "    label_embedding = get_embedding(label_lower).reshape(1, -1)\n",
    "\n",
    "    if label_map:\n",
    "        label_keys = list(label_map.keys())\n",
    "        label_embeddings = np.array([get_embedding(k) for k in label_keys]).squeeze(1)\n",
    "\n",
    "        # Đảm bảo đúng shape\n",
    "        if len(label_embeddings.shape) == 1:\n",
    "            label_embeddings = label_embeddings.reshape(1, -1)\n",
    "\n",
    "        # Tính cosine similarity\n",
    "        similarities = cosine_similarity(label_embedding, label_embeddings).flatten()\n",
    "\n",
    "        # Chọn thực thể gần nhất\n",
    "        merged_list = list(zip(label_keys, similarities))\n",
    "        sorted_list = sorted(merged_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_list and sorted_list[0][1] > similarity_threshold:\n",
    "            return label_map[sorted_list[0][0]]\n",
    "\n",
    "    # Nếu không tìm thấy, thử trong KB (FACC1)\n",
    "    facc1_cand_entities = facc1_index.get_indexrange_entity_el_pro_one_mention(label_lower, top_k=top_k)\n",
    "    if facc1_cand_entities:\n",
    "        best_match = max(facc1_cand_entities.items(), key=lambda x: x[1])\n",
    "        return best_match[0]\n",
    "\n",
    "    return label  # Trả về label nếu không tìm thấy\n",
    "\n",
    "def parse_nsexpr(expr):\n",
    "    \"\"\"\n",
    "    Chuyển chuỗi biểu thức thành cây cấu trúc dạng nested list.\n",
    "    Hàm này dùng duyệt ký tự, khi gặp '(' sẽ tìm phần con cho đến khi khớp với ')',\n",
    "    và giữ nguyên nội dung trong ngoặc vuông.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(expr):\n",
    "        if expr[i].isspace():\n",
    "            i += 1\n",
    "        elif expr[i] == '(':\n",
    "            # Tìm phần con của biểu thức trong ngoặc đơn\n",
    "            count = 1\n",
    "            j = i + 1\n",
    "            while j < len(expr) and count > 0:\n",
    "                if expr[j] == '(':\n",
    "                    count += 1\n",
    "                elif expr[j] == ')':\n",
    "                    count -= 1\n",
    "                j += 1\n",
    "            # Đệ quy phân tích phần con (loại bỏ ngoặc bao ngoài)\n",
    "            subtree = parse_nsexpr(expr[i+1:j-1])\n",
    "            tokens.append(subtree)\n",
    "            i = j\n",
    "        elif expr[i] == '[':\n",
    "            # Giữ nguyên nội dung trong ngoặc vuông\n",
    "            j = expr.find(']', i)\n",
    "            if j == -1:\n",
    "                return \"\"\n",
    "                raise ValueError(\"Không tìm thấy dấu ']' kết thúc.\")\n",
    "                \n",
    "            token = expr[i:j+1].strip()\n",
    "            tokens.append(token)\n",
    "            i = j + 1\n",
    "        else:\n",
    "            # Đọc một token cho đến khi gặp khoảng trắng hoặc ngoặc\n",
    "            j = i\n",
    "            while j < len(expr) and (not expr[j].isspace()) and expr[j] not in ['(', ')']:\n",
    "                j += 1\n",
    "            tokens.append(expr[i:j])\n",
    "            i = j\n",
    "    return tokens\n",
    "\n",
    "def collect_labels(tree):\n",
    "    \"\"\"\n",
    "    Duyệt cây cấu trúc (nested list) để thu thập các nhãn của quan hệ và thực thể.\n",
    "    Giả sử:\n",
    "      - Biểu thức JOIN có dạng: [\"JOIN\", relation_part, entity_part]\n",
    "      - Phần relation_part: nếu là list và bắt đầu bằng \"R\", thì phần thứ hai chứa nhãn quan hệ (dạng \"[ label ]\"). \n",
    "        Nếu là chuỗi dạng \"[ label ]\" thì đó cũng là nhãn quan hệ.\n",
    "      - Phần entity_part: nếu là chuỗi dạng \"[ label ]\" thì đó là nhãn thực thể, nếu là list thì xử lý đệ quy.\n",
    "      - Biểu thức AND sẽ có nhiều biểu thức con.\n",
    "    \"\"\"\n",
    "    relations = []\n",
    "    entities = []\n",
    "    \n",
    "    if isinstance(tree, list) and tree:\n",
    "        # Nếu token đầu tiên là JOIN hoặc AND\n",
    "        op = tree[0]\n",
    "        if isinstance(op, str):\n",
    "            op_upper = op.upper()\n",
    "        else:\n",
    "            op_upper = \"\"\n",
    "        \n",
    "        if op_upper == \"JOIN\":\n",
    "            # Xử lý phần quan hệ\n",
    "            if len(tree) >= 2:\n",
    "                rel_part = tree[1]\n",
    "                # Nếu là list dạng [ \"R\", \"[ label ]\" ]\n",
    "                if isinstance(rel_part, list) and len(rel_part) >= 2 and isinstance(rel_part[0], str) and rel_part[0].upper() == \"R\":\n",
    "                    token = rel_part[1]\n",
    "                    if isinstance(token, str) and token.startswith('[') and token.endswith(']'):\n",
    "                        rel_label = token[1:-1].strip()\n",
    "                        relations.append(rel_label)\n",
    "                # Nếu là chuỗi dạng \"[ label ]\"\n",
    "                elif isinstance(rel_part, str) and rel_part.startswith('[') and rel_part.endswith(']'):\n",
    "                    rel_label = rel_part[1:-1].strip()\n",
    "                    relations.append(rel_label)\n",
    "                else:\n",
    "                    # Nếu không đúng định dạng, duyệt đệ quy\n",
    "                    sub_rel, sub_ent = collect_labels(rel_part)\n",
    "                    relations.extend(sub_rel)\n",
    "                    entities.extend(sub_ent)\n",
    "            # Xử lý phần thực thể\n",
    "            if len(tree) >= 3:\n",
    "                ent_part = tree[2]\n",
    "                if isinstance(ent_part, list):\n",
    "                    sub_rel, sub_ent = collect_labels(ent_part)\n",
    "                    relations.extend(sub_rel)\n",
    "                    entities.extend(sub_ent)\n",
    "                elif isinstance(ent_part, str) and ent_part.startswith('[') and ent_part.endswith(']'):\n",
    "                    ent_label = ent_part[1:-1].strip()\n",
    "                    entities.append(ent_label)\n",
    "        elif op_upper == \"AND\":\n",
    "            # Với AND, duyệt tất cả các phần con\n",
    "            for sub in tree[1:]:\n",
    "                sub_rel, sub_ent = collect_labels(sub)\n",
    "                relations.extend(sub_rel)\n",
    "                entities.extend(sub_ent)\n",
    "        else:\n",
    "            # Nếu không phải JOIN hay AND, duyệt tất cả các phần tử nếu chúng là list\n",
    "            for elem in tree:\n",
    "                if isinstance(elem, list):\n",
    "                    sub_rel, sub_ent = collect_labels(elem)\n",
    "                    relations.extend(sub_rel)\n",
    "                    entities.extend(sub_ent)\n",
    "    return relations, entities\n",
    "\n",
    "\n",
    "\n",
    "def extract_entities_and_relations(normed_expr):\n",
    "\n",
    "    if not normed_expr or len(normed_expr) == 0:  # Kiểm tra nếu normed_expr rỗng\n",
    "        return [], []\n",
    "    \n",
    "    if normed_expr[0] != \"(\":\n",
    "        return [], []\n",
    "    \n",
    "    tree = parse_nsexpr(normed_expr)\n",
    "    if tree is None:\n",
    "        return [], []  # Trả về danh sách rỗng nếu parse thất bại\n",
    "    \n",
    "    return collect_labels(tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entity(label, label_map, facc1_index, top_k=20, similarity_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Tìm thực thể hoặc quan hệ từ gold maps, SimCSE hoặc FACC1.\n",
    "    \"\"\"\n",
    "    label_lower = label.lower()\n",
    "\n",
    "    # Nếu có trong label_map, trả về ngay\n",
    "    if label_map and label_lower in label_map:\n",
    "        return label_map[label_lower]\n",
    "\n",
    "    # Lấy embedding cho label\n",
    "    label_embedding = get_embedding(label_lower).reshape(1, -1)\n",
    "\n",
    "    if label_map:\n",
    "        label_keys = list(label_map.keys())\n",
    "        label_embeddings = np.array([get_embedding(k) for k in label_keys]).squeeze(1)\n",
    "        label_embedding = normalize(label_embedding, axis=1)\n",
    "        label_embeddings = normalize(label_embeddings, axis=1)\n",
    "        # Tính cosine similarity\n",
    "        similarities = cosine_similarity(label_embedding, label_embeddings).flatten()\n",
    "        # Chọn thực thể gần nhất\n",
    "        merged_list = list(zip(label_keys, similarities))\n",
    "        sorted_list = sorted(merged_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_list and sorted_list[0][1] > similarity_threshold:\n",
    "            return label_map[sorted_list[0][0]]\n",
    "\n",
    "    # Nếu không tìm thấy, thử trong KB (FACC1)\n",
    "    facc1_cand_entities = facc1_index.get_indexrange_entity_el_pro_one_mention(label_lower, top_k=top_k)\n",
    "    if facc1_cand_entities:\n",
    "        temp = []\n",
    "        for key in list(facc1_cand_entities.keys())[1:]:\n",
    "            if facc1_cand_entities[key] >= 0.001:\n",
    "                temp.append(key)\n",
    "        if len(temp) > 0:\n",
    "            label = [list(facc1_cand_entities.keys())[0]]+temp\n",
    "        else:\n",
    "            label = list(facc1_cand_entities.keys())[0]\n",
    "\n",
    "    return label  # Trả về label nếu không tìm thấy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relation(label, label_map, relation_kb_map, facc1_index, top_k=20, similarity_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Tìm quan hệ từ gold maps, SimCSE hoặc FACC1.\n",
    "    \"\"\"\n",
    "    label_lower = label.lower()\n",
    "\n",
    "    # 🔹 BƯỚC 1: Kiểm tra nếu đã có sẵn trong `label_map`\n",
    "    if label_map and label_lower in label_map:\n",
    "        return label_map[label_lower]\n",
    "\n",
    "    # 🔹 BƯỚC 2: Kiểm tra nếu có sẵn trong `relation_kb_map`\n",
    "    if relation_kb_map and label_lower in relation_kb_map:\n",
    "        return relation_kb_map[label_lower]  # ⏩ Trả về ngay nếu có sẵn\n",
    "\n",
    "    # 🔹 BƯỚC 3: Tính toán embedding và tìm quan hệ gần nhất bằng cosine similarity\n",
    "    label_embedding = get_embedding(label_lower).reshape(1, -1)\n",
    "\n",
    "    if label_map:\n",
    "        label_keys = list(label_map.keys())\n",
    "        label_embeddings = np.array([get_embedding(k) for k in label_keys]).squeeze(1)\n",
    "        label_embedding = normalize(label_embedding, axis=1)\n",
    "        label_embeddings = normalize(label_embeddings, axis=1)\n",
    "\n",
    "        similarities = cosine_similarity(label_embedding, label_embeddings).flatten()\n",
    "        sorted_list = sorted(zip(label_keys, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_list and sorted_list[0][1] > similarity_threshold:\n",
    "            return label_map[sorted_list[0][0]]\n",
    "\n",
    "    if relation_kb_map:\n",
    "        label_keys = list(relation_kb_map.keys())\n",
    "        label_embeddings = np.array([get_embedding(k) for k in label_keys]).squeeze(1)\n",
    "        label_embedding = normalize(label_embedding, axis=1)\n",
    "        label_embeddings = normalize(label_embeddings, axis=1)\n",
    "\n",
    "        similarities = cosine_similarity(label_embedding, label_embeddings).flatten()\n",
    "        sorted_list = sorted(zip(label_keys, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_list and sorted_list[0][1] > similarity_threshold:\n",
    "            return relation_kb_map[sorted_list[0][0]]\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SExpressionParser:\n",
    "    def __init__(self):\n",
    "        self.var_counter = 1  # Đếm số biến trung gian (?X1, ?X2, ...)\n",
    "\n",
    "    def get_new_var(self):\n",
    "        \"\"\"Tạo biến trung gian mới.\"\"\"\n",
    "        var_name = f\"?X{self.var_counter}\"\n",
    "        self.var_counter += 1\n",
    "        return var_name\n",
    "\n",
    "    def parse_s_expr(self, s_expr):\n",
    "        \"\"\"Chuyển đổi S-Expression thành danh sách lồng nhau.\"\"\"\n",
    "        s_expr = re.sub(r'\\(', ' ( ', s_expr)\n",
    "        s_expr = re.sub(r'\\)', ' ) ', s_expr)\n",
    "        tokens = s_expr.split()\n",
    "        return self.build_tree(tokens)\n",
    "\n",
    "    def build_tree(self, tokens):\n",
    "        \"\"\"Chuyển đổi danh sách token thành cây lồng nhau.\"\"\"\n",
    "        if not tokens:\n",
    "            return None\n",
    "        token = tokens.pop(0)\n",
    "        if token == \"(\":\n",
    "            sub_expr = []\n",
    "            while tokens[0] != \")\":\n",
    "                sub_expr.append(self.build_tree(tokens))\n",
    "            tokens.pop(0)  # Bỏ dấu \")\"\n",
    "            return sub_expr\n",
    "        elif token == \")\":\n",
    "            raise ValueError(\"Unexpected ')'\")\n",
    "        else:\n",
    "            return token\n",
    "\n",
    "    def process_join(self, expr, target_var):\n",
    "        \"\"\"\n",
    "        Xử lý JOIN, tạo triple SPARQL.\n",
    "        \"\"\"\n",
    "        triples = []\n",
    "        if not isinstance(expr, list):\n",
    "            return expr, triples\n",
    "\n",
    "        if expr[0] == \"AND\":\n",
    "            # Xử lý từng JOIN trong AND riêng lẻ\n",
    "            for sub_expr in expr[1:]:\n",
    "                _, sub_triples = self.process_join(sub_expr, target_var)\n",
    "                triples.extend(sub_triples)\n",
    "            return target_var, triples\n",
    "\n",
    "        if expr[0] == \"JOIN\":\n",
    "            right_expr = expr[2]\n",
    "            right_triples = []\n",
    "            if isinstance(right_expr, list) and right_expr[0] == \"JOIN\":\n",
    "                right_var, right_triples = self.process_join(right_expr, self.get_new_var())\n",
    "            else: \n",
    "                right_var = right_expr\n",
    "            \n",
    "            # Xử lý nhánh trái\n",
    "            left_expr = expr[1]\n",
    "            if isinstance(left_expr, list) and left_expr[0] == \"R\":\n",
    "                rel = left_expr[1]\n",
    "                right = right_var\n",
    "                left = target_var\n",
    "                if right[0] != '?':\n",
    "                    right = \"wd:\" + right\n",
    "                if left[0] !='?':\n",
    "                    left = \"wd:\" + left   \n",
    "                triples.append([right, f\"wdt:{rel}\", left])\n",
    "            else:\n",
    "                right = right_var\n",
    "                left = target_var\n",
    "                if right[0] != '?':\n",
    "                    right = \"wd:\" + right\n",
    "                if left[0] !='?':\n",
    "                    left = \"wd:\" + left   \n",
    "                triples.append([left, f\"wdt:{left_expr}\", right])\n",
    "\n",
    "            # Thêm các triples từ nhánh phải trước khi thêm triple chính\n",
    "            triples = right_triples + triples\n",
    "            return target_var, triples\n",
    "\n",
    "        return expr, triples\n",
    "\n",
    "    def s_expr_to_sparql(self, s_expr):\n",
    "        \"\"\"Chuyển đổi từ S-Expression sang SPARQL.\"\"\"\n",
    "        if s_expr.count(\"(\") != s_expr.count(\")\"):\n",
    "            return None\n",
    "        if s_expr.count(\"[\") != s_expr.count(\"]\"):\n",
    "            return None\n",
    "        parsed_expr = self.parse_s_expr(s_expr)\n",
    "        target_var = \"?answer\"\n",
    "        final_var, triples = self.process_join(parsed_expr, target_var)\n",
    "\n",
    "        sparql_body = \"\\n  \".join([\" \".join(t) + \" .\" for t in triples])\n",
    "        sparql_query = f\"\"\"PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "SELECT DISTINCT {target_var} WHERE {{ \n",
    "  {sparql_body}\n",
    "}}\"\"\"\n",
    "        return sparql_query\n",
    "\n",
    "import requests    \n",
    "WIKIDATA_SPARQL_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "WIKIDATA_API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "def execute_query_with_odbc(sparql_query):\n",
    "    \"\"\"Truy vấn Wikidata và trả về danh sách câu trả lời (bao gồm tất cả biến)\"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\", \"Accept\": \"application/sparql-results+json\"}\n",
    "    response = requests.get(WIKIDATA_SPARQL_ENDPOINT, params={\"query\": sparql_query, \"format\": \"json\"}, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"results\", {}).get(\"bindings\", [])\n",
    "        answers = []\n",
    "\n",
    "        for result in results:\n",
    "            for var in result:  # Duyệt qua tất cả các biến trả về\n",
    "                value = result[var][\"value\"]\n",
    "                answers.append(value)  # Chấp nhận tất cả giá trị, không chỉ thực thể Wikidata\n",
    "\n",
    "        return answers  # Trả về toàn bộ danh sách kết quả\n",
    "\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_normed_to_s_expression(normed_expr, gold_relation_map, gold_entity_map, relation_KB_map, facc1_index):\n",
    "    \"\"\"\n",
    "    Chuyển đổi từ normed_sexpression sang s_expression.\n",
    "    Sau khi trích xuất các nhãn quan hệ và thực thể từ normed_expr,\n",
    "    ta lấy danh sách các mã ứng viên cho mỗi nhãn và tạo hoán vị giữa các cặp ứng viên đó.\n",
    "    Kết quả trả về là một danh sách các s_expression khả dĩ.\n",
    "    \"\"\"\n",
    "    normed_expr = fix_unbalanced_parentheses(normed_expr)\n",
    "    # Trích xuất các nhãn quan hệ và thực thể từ biểu thức\n",
    "    relations, entities = extract_entities_and_relations(normed_expr)\n",
    "    \n",
    "    # Tạo mapping từ token xuất hiện trong biểu thức sang danh sách các ứng viên mã.\n",
    "    # Ví dụ: token_str = \"[ author ]\"\n",
    "    candidate_map = {}\n",
    "    for rel in relations:\n",
    "        token = f'[ {rel} ]'\n",
    "        candidate = find_relation(rel, gold_relation_map, relation_KB_map, facc1_index)\n",
    "        # Nếu candidate không phải danh sách, chuyển nó thành danh sách để tạo hoán vị\n",
    "        if not isinstance(candidate, list):\n",
    "            candidate = [candidate]\n",
    "        candidate_map[token] = candidate\n",
    "        \n",
    "    for ent in entities:\n",
    "        token = f'[ {ent} ]'\n",
    "        candidate = find_entity(ent, gold_entity_map , facc1_index)\n",
    "        if not isinstance(candidate, list):\n",
    "            candidate = [candidate]\n",
    "        candidate_map[token] = candidate\n",
    "    \n",
    "    # Nếu không có token nào cần thay thế, trả về biểu thức gốc\n",
    "    if not candidate_map:\n",
    "        return [normed_expr]\n",
    "    \n",
    "    # Lấy danh sách các token và danh sách các danh sách ứng viên tương ứng\n",
    "    tokens = list(candidate_map.keys())\n",
    "    candidate_lists = [candidate_map[token] for token in tokens]\n",
    "    \n",
    "    # Tạo tất cả các hoán vị ứng viên (Cartesian product)\n",
    "    all_combinations = list(product(*candidate_lists))\n",
    "    \n",
    "    s_expressions = []\n",
    "    for comb in all_combinations:\n",
    "        temp_expr = normed_expr\n",
    "        # Với mỗi token, thay thế bằng ứng viên tương ứng theo hoán vị\n",
    "        for token, replacement in zip(tokens, comb):\n",
    "            temp_expr = temp_expr.replace(token, replacement)\n",
    "        s_expressions.append(temp_expr)\n",
    "    \n",
    "    return s_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Đọc file JSONL và trả về danh sách các object\"\"\"\n",
    "\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read().replace('(EXPECTED RESULT)', 'null').replace('(QUESTION)', 'null')\n",
    "\n",
    "    try:\n",
    "        data = ujson.loads(content)\n",
    "        print(\"JSON loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prf1(gold_answers, pred_answers):\n",
    "    \"\"\"Tính Precision, Recall, F1-score\"\"\"\n",
    "    if len(gold_answers) == 0:\n",
    "        if len(pred_answers) == 0:\n",
    "            return [1.0, 1.0, 1.0]  # Đúng khi không có câu trả lời\n",
    "        else:\n",
    "            return [0.0, 1.0, 0.0]\n",
    "    elif len(pred_answers) == 0:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    tp = 1e-40  # numerical trick\n",
    "\n",
    "    tp = tp + len(set(gold_answers) & set(pred_answers))\n",
    "\n",
    "    fp = len(set(pred_answers) - set(gold_answers))\n",
    "    fn = len(set(gold_answers) - set(pred_answers))\n",
    "    precision = tp / (tp + fp) \n",
    "    recall = tp / (tp + fn) \n",
    "    f1 = (2 * precision * recall) / (precision + recall) \n",
    "\n",
    "    return [precision, recall, f1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON loaded successfully!\n",
      "JSON loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu\n",
    "predictions = load_jsonl(\"LLMs/beam_prediction/generated_predictions_beam_Q7b.json\")\n",
    "gold_data = load_jsonl(\"Data/LC-QuAD2.0/label_map/LC-QuAD2.0_test.json\")\n",
    "gold_data = gold_data[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load danh sách quan hệ trong KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"property_list_file_wikidata_complete_all_mention\"\n",
    "\n",
    "relation_KB_map = {}\n",
    "\n",
    "# Đọc file và đảo ngược quan hệ\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")  # Tách theo tab\n",
    "        if len(parts) == 2:\n",
    "            relation_KB_map[parts[1]] = parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_cnt = 0\n",
    "top_hit = 0\n",
    "failed_preds = []\n",
    "final_executable_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang đánh giá:   0%|          | 0/1000 [05:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lag_result:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m set_query \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_normed_to_s_expression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_relation_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_entity_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_KB_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfacc1_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m set_query:\n\u001b[0;32m     34\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m, in \u001b[0;36mconvert_normed_to_s_expression\u001b[1;34m(normed_expr, gold_relation_map, gold_entity_map, relation_KB_map, facc1_index)\u001b[0m\n\u001b[0;32m      8\u001b[0m normed_expr \u001b[38;5;241m=\u001b[39m fix_unbalanced_parentheses(normed_expr)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Trích xuất các nhãn quan hệ và thực thể từ biểu thức\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m relations, entities \u001b[38;5;241m=\u001b[39m \u001b[43mextract_entities_and_relations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormed_expr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Tạo mapping từ token xuất hiện trong biểu thức sang danh sách các ứng viên mã.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Ví dụ: token_str = \"[ author ]\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m candidate_map \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[6], line 179\u001b[0m, in \u001b[0;36mextract_entities_and_relations\u001b[1;34m(normed_expr)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normed_expr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], []\n\u001b[1;32m--> 179\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43mparse_nsexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormed_expr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tree \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], []  \u001b[38;5;66;03m# Trả về danh sách rỗng nếu parse thất bại\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 98\u001b[0m, in \u001b[0;36mparse_nsexpr\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Đọc một token cho đến khi gặp khoảng trắng hoặc ngoặc\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     j \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m expr[j]\u001b[38;5;241m.\u001b[39misspace()) \u001b[38;5;129;01mand\u001b[39;00m expr[j] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     99\u001b[0m         j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    100\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mappend(expr[i:j])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 300  # Số dòng mỗi batch\n",
    "LOG_FILE = \"progress_log.txt\"\n",
    "\n",
    "results = []\n",
    "simcse_model = model  # Mô hình SimCSE của bạn\n",
    "facc1_index = surface_index\n",
    "parser = SExpressionParser()\n",
    "start_time = time.perf_counter()  # Bắt đầu đo thời gian\n",
    "\n",
    "# Ghi log\n",
    "with open(LOG_FILE, \"w\", encoding=\"utf-8\") as log_file:\n",
    "    log_file.write(\"Bắt đầu quá trình đánh giá\\n\")\n",
    "\n",
    "for i, (pred, gold) in enumerate(tqdm(zip(predictions, gold_data), total=len(predictions), desc=\"Đang đánh giá\")):\n",
    "    try:\n",
    "        gold_entity_map = {v.lower(): k for k, v in gold['gold_entity_map'].items()}\n",
    "        gold_relation_map = {v.lower(): k for k, v in gold['gold_relation_map'].items()}\n",
    "        gold_answers = gold.get(\"answer\", [])\n",
    "        executable_index = None\n",
    "        best_f1, best_precision, best_recall = 0, 0, 0\n",
    "        kq = []\n",
    "        lag_result = False\n",
    "        denormed_pred = []\n",
    "        for rank, query in enumerate(pred['predicted_query']):\n",
    "            if lag_result:\n",
    "                break\n",
    "\n",
    "            set_query = convert_normed_to_s_expression(query, gold_relation_map, gold_entity_map, relation_KB_map , facc1_index)\n",
    "            for q in set_query:\n",
    "                query_result = []\n",
    "                if not q:\n",
    "                    continue\n",
    "                if rank == 0 and q.lower() ==gold['s_expr'].lower():\n",
    "                    ex_cnt +=1\n",
    "                sparql = convert_s_expression_to_sparql(q)\n",
    "                if sparql == \"UNKNOWN\":\n",
    "                    continue\n",
    "                denormed_pred.append(sparql)\n",
    "                query_result = execute_query_with_odbc(sparql)\n",
    "                if query_result:\n",
    "                    if rank == 0:\n",
    "                        top_hit += 1\n",
    "                    executable_index = rank\n",
    "                    precision, recall, f1 = calculate_prf1(gold_answers, query_result)\n",
    "                    if f1 > best_f1:\n",
    "                        kq = query_result\n",
    "                        best_f1, best_precision, best_recall = f1, precision, recall\n",
    "                    if precision == 1:\n",
    "                        lag_result = True\n",
    "                        break\n",
    "        if executable_index is not None:\n",
    "            final_executable_cnt+=1\n",
    "        else:\n",
    "            failed_preds.append({'qid':gold[\"question_id\"], \n",
    "                'gt_sexpr': gold['s_expr'], \n",
    "                'gt_normed_sexpr': pred['gen_label'],\n",
    "                'pred': pred, \n",
    "                'denormed_pred':denormed_pred})    \n",
    "        results.append({\n",
    "            \"qid\": gold[\"question_id\"],\n",
    "            \"answer\": gold_answers,\n",
    "            \"result\": kq,\n",
    "            \"nor_s_expr\":gold[\"nor_s_expr\"],\n",
    "            \"precision\": best_precision,\n",
    "            \"recall\": best_recall,\n",
    "            \"f1\": best_f1\n",
    "        })\n",
    "\n",
    "        # Ghi log tiến trình xử lý\n",
    "        with open(LOG_FILE, \"a\", encoding=\"utf-8\") as log_file:\n",
    "            log_file.write(f\"Đã xử lý xong dòng {i + 1}/{len(predictions)}\\n\")\n",
    "\n",
    "        # Khi đủ 100 kết quả, lưu vào file và reset biến `results`\n",
    "        if (i + 1) % BATCH_SIZE == 0 or (i + 1) == len(predictions):\n",
    "            batch_id = (i + 1) // BATCH_SIZE\n",
    "            filename = f\"LLMs/eval_result/evaluation_vinallamaQ7b_part_{batch_id}.json\"\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "            print(f\"✅ Đã lưu {len(results)} dòng vào {filename}\")\n",
    "            results = []  # Reset danh sách kết quả\n",
    "\n",
    "    except Exception as e:\n",
    "        with open(LOG_FILE, \"a\", encoding=\"utf-8\") as log_file:\n",
    "            log_file.write(f\"Lỗi tại dòng {i + 1}: {str(e)}\\n\")\n",
    "        print(f\"❌ Lỗi tại dòng {i + 1}: {e}\")\n",
    "\n",
    "# Kết thúc đo thời gian\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "print(f\"🎯 Quá trình đánh giá hoàn tất trong {total_time:.2f} giây!\")\n",
    "\n",
    "with open(LOG_FILE, \"a\", encoding=\"utf-8\") as log_file:\n",
    "    log_file.write(f\"Quá trình đánh giá hoàn tất trong {total_time:.2f} giây!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STR Match 0.34690943938667945\n",
      "TOP 1 Executable 0.45759463344513657\n",
      "Final Executable 0.6411116435074269\n"
     ]
    }
   ],
   "source": [
    "print('STR Match', ex_cnt/ len(predictions))\n",
    "print('TOP 1 Executable', top_hit/ len(predictions))\n",
    "print('Final Executable', final_executable_cnt/ len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_Match = ex_cnt/ len(predictions)\n",
    "TOP1_Executable = top_hit/ len(predictions)\n",
    "Final_Executable = final_executable_cnt/ len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Precision: 0.51899\n",
      "📊 Recall: 0.53568\n",
      "📊 F1-score: 0.51993\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Danh sách các file kết quả đánh giá\n",
    "file_list = glob.glob(\"LLMs/eval_result/evaluation_vinallamaQ7b_part_*.json\")\n",
    "\n",
    "# Biến để tổng hợp kết quả\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Đọc từng file và tổng hợp dữ liệu\n",
    "for file in file_list:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for entry in data:\n",
    "            total_precision += entry.get(\"precision\", 0)\n",
    "            total_recall += entry.get(\"recall\", 0)\n",
    "            total_f1 += entry.get(\"f1\", 0)\n",
    "            total_samples += 1\n",
    "\n",
    "# Tránh chia cho 0\n",
    "if total_samples > 0:\n",
    "    avg_precision = total_precision / total_samples\n",
    "    avg_recall = total_recall / total_samples\n",
    "    avg_f1 = total_f1 / total_samples\n",
    "else:\n",
    "    avg_precision, avg_recall, avg_f1, hits_at_1 = 0, 0, 0, 0\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(f\"📊 Precision: {avg_precision:.5f}\")\n",
    "print(f\"📊 Recall: {avg_recall:.5f}\")\n",
    "print(f\"📊 F1-score: {avg_f1:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kết quả đã được lưu vào LLMs/eval_result/Final_evaluation_27b.json\n"
     ]
    }
   ],
   "source": [
    "# Tạo dữ liệu kết quả đánh giá\n",
    "eval_results = {\n",
    "    \"precision\": avg_precision,\n",
    "    \"recall\": avg_recall,\n",
    "    \"f1\": avg_f1,\n",
    "    \"STR Match\": STR_Match,\n",
    "    \"Hit@1\": TOP1_Executable,\n",
    "    \"Final_Executable\": Final_Executable, \n",
    "}\n",
    "\n",
    "# Lưu vào file JSON\n",
    "output_file = \"LLMs/eval_result/Final_evaluation_Q7b.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(eval_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Kết quả đã được lưu vào {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kết quả đã được lưu vào LLMs/eval_result/Failed_result_27b.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_file = \"LLMs/eval_result/Failed_result_Q7b.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(failed_preds, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Kết quả đã được lưu vào {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
