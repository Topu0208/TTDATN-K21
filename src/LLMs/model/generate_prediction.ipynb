{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10883031,"sourceType":"datasetVersion","datasetId":6762542},{"sourceId":11012996,"sourceType":"datasetVersion","datasetId":6856844},{"sourceId":11014583,"sourceType":"datasetVersion","datasetId":6857890},{"sourceId":284288,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":243623,"modelId":265247},{"sourceId":285432,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":244630,"modelId":266253}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import PeftModel, PeftConfig\nimport json\nfrom tqdm import tqdm\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:47:09.655212Z","iopub.execute_input":"2025-03-14T13:47:09.655900Z","iopub.status.idle":"2025-03-14T13:47:40.125643Z","shell.execute_reply.started":"2025-03-14T13:47:09.655877Z","shell.execute_reply":"2025-03-14T13:47:40.124751Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/data-val/examples.json\n/kaggle/input/model_update_val/pytorch/default/1/model/adapter_model.safetensors\n/kaggle/input/model_update_val/pytorch/default/1/model/adapter_config.json\n/kaggle/input/model_update_val/pytorch/default/1/model/README.md\n/kaggle/input/model_update_val/pytorch/default/1/model/tokenizer.json\n/kaggle/input/model_update_val/pytorch/default/1/model/tokenizer_config.json\n/kaggle/input/model_update_val/pytorch/default/1/model/special_tokens_map.json\n/kaggle/input/vina7b_lora_3epoch/pytorch/default/1/model/adapter_model.safetensors\n/kaggle/input/vina7b_lora_3epoch/pytorch/default/1/model/adapter_config.json\n/kaggle/input/vina7b_lora_3epoch/pytorch/default/1/model/README.md\n/kaggle/input/vina7b_lora_3epoch/pytorch/default/1/model/tokenizer.json\n/kaggle/input/vina7b_lora_3epoch/pytorch/default/1/model/tokenizer_config.json\n/kaggle/input/vina7b_lora_3epoch/pytorch/default/1/model/special_tokens_map.json\n/kaggle/input/test-set-data/examples.json\n/kaggle/input/data-test/examples.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers accelerate peft bitsandbytes datasets huggingface_hub trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:47:40.126611Z","iopub.execute_input":"2025-03-14T13:47:40.127231Z","iopub.status.idle":"2025-03-14T13:47:48.684093Z","shell.execute_reply.started":"2025-03-14T13:47:40.127205Z","shell.execute_reply":"2025-03-14T13:47:48.683038Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\nCollecting trl\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: trl, bitsandbytes\nSuccessfully installed bitsandbytes-0.45.3 trl-0.15.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport transformers\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:47:48.685249Z","iopub.execute_input":"2025-03-14T13:47:48.685501Z","iopub.status.idle":"2025-03-14T13:47:48.689514Z","shell.execute_reply.started":"2025-03-14T13:47:48.685480Z","shell.execute_reply":"2025-03-14T13:47:48.688723Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model_name = \"/kaggle/input/vina7b_lora_3epoch/pytorch/default/1/model\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",  # âœ… Tá»± Ä‘á»™ng sá»­ dá»¥ng cáº£ 2 GPU\n    torch_dtype = torch.float16\n)\n# ğŸ”¹ Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\nprint(\"âœ… MÃ´ hÃ¬nh Ä‘Ã£ táº£i thÃ nh cÃ´ng!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:47:48.690334Z","iopub.execute_input":"2025-03-14T13:47:48.690653Z","iopub.status.idle":"2025-03-14T13:50:41.663496Z","shell.execute_reply.started":"2025-03-14T13:47:48.690622Z","shell.execute_reply":"2025-03-14T13:50:41.662484Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/671 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31cfe8a192f4a71b84fdebb77b9c3e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0fbd63f3b08499ab63447319c756f49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c76d03783aa4ff08db6c51a4eac32de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d38870baa1f48988b5c17f5f8d15ba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.80G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c12c854b711439ea848b988ccf25946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783f16a40c8e4d148cc8d56ddc8dafaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0330b389ba3b48b79526648a2d8f2c81"}},"metadata":{}},{"name":"stdout","text":"âœ… MÃ´ hÃ¬nh Ä‘Ã£ táº£i thÃ nh cÃ´ng!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:50:41.664469Z","iopub.execute_input":"2025-03-14T13:50:41.664823Z","iopub.status.idle":"2025-03-14T13:50:41.668788Z","shell.execute_reply.started":"2025-03-14T13:50:41.664791Z","shell.execute_reply":"2025-03-14T13:50:41.667869Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/input/data-test/examples.json\", \"r\", encoding=\"utf-8\") as f:\n    json_data = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:50:41.670727Z","iopub.execute_input":"2025-03-14T13:50:41.670999Z","iopub.status.idle":"2025-03-14T13:50:43.640499Z","shell.execute_reply.started":"2025-03-14T13:50:41.670977Z","shell.execute_reply":"2025-03-14T13:50:43.639813Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import re\n\ndef generate_query(question, history=[]):\n    # Äá»‹nh dáº¡ng láº¡i lá»‹ch sá»­ há»™i thoáº¡i\n    history_text = \"\\n\".join(history) if history else \"\"\n\n    # XÃ¢y dá»±ng input text\n    input_text = f\"\"\"### Instruction:\nTáº¡o truy váº¥n Logical Form Ä‘á»ƒ láº¥y thÃ´ng tin tÆ°Æ¡ng á»©ng vá»›i cÃ¢u há»i Ä‘Ã£ cho.\n\n### Input:\nQuestion: {question}\n\n### History:\n{history_text}\n\n### Output:\n\"\"\"\n\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n\n    output_ids = model.generate(\n        input_ids, \n        max_new_tokens=96,\n        num_beams=5,\n        num_beam_groups=1,  \n        num_return_sequences=5,\n        eos_token_id=tokenizer.eos_token_id,\n        do_sample=True,\n        temperature = 0.95,\n        top_p = 0.7,\n        repetition_penalty = 1.0,\n        length_penalty = 1.0\n    )\n    \n    def clean_output(text):\n        text = text.split(\"Output:\")[-1].strip()  \n        text = re.split(r\"\\n+\", text)[0]  # Láº¥y dÃ²ng Ä‘áº§u tiÃªn\n        return text\n\n    output_texts = [clean_output(tokenizer.decode(out, skip_special_tokens=True)) for out in output_ids]\n    \n    return output_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:50:43.641579Z","iopub.execute_input":"2025-03-14T13:50:43.641879Z","iopub.status.idle":"2025-03-14T13:50:43.647818Z","shell.execute_reply.started":"2025-03-14T13:50:43.641849Z","shell.execute_reply":"2025-03-14T13:50:43.647168Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"query1 = generate_query(\"Ná»¯ diá»…n viÃªn nÃ o lÃ  ngÆ°á»i lá»“ng tiáº¿ng cho bá»™ phim South Park vÃ  Ä‘Æ°á»£c thuÃª lÃ m ca sÄ©?\")\nquery2 = generate_query(\"TrÃªn há»“ Winnipeg cÃ³ nhá»¯ng há»“ nÃ o trÃªn sÃ´ng?\")\nquery3 = generate_query(\"ai Ä‘Ã£ káº¿t hÃ´n vá»›i diá»…n viÃªn cá»§a Bepanaah?\")\n\nprint(\"ğŸ“Œ Truy váº¥n 1:\", query1)\nprint(\"ğŸ“Œ Truy váº¥n 2:\", query2)\nprint(\"ğŸ“Œ Truy váº¥n 3:\", query3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:50:43.648679Z","iopub.execute_input":"2025-03-14T13:50:43.648934Z","iopub.status.idle":"2025-03-14T13:50:55.547481Z","shell.execute_reply.started":"2025-03-14T13:50:43.648908Z","shell.execute_reply":"2025-03-14T13:50:55.546538Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Œ Truy váº¥n 1: ['( AND ( JOIN ( R [ diá»…n viÃªn lá»“ng tiáº¿ng ] ) [ South Park ] ) ( JOIN [ nghá» nghiá»‡p ] [ ca sÄ© ] ) )', '( AND ( JOIN ( R [ diá»…n viÃªn lá»“ng tiáº¿ng ] ) [ South Park ] ) ( JOIN [ ngÆ°á»i biá»ƒu diá»…n ] [ Justin Timberlake ] ) )', '( AND ( JOIN ( R [ diá»…n viÃªn lá»“ng tiáº¿ng ] ) [ South Park ] ) ( JOIN [ ngÆ°á»i biá»ƒu diá»…n ] [ Cher ] ) )', '( JOIN ( R [ diá»…n viÃªn lá»“ng tiáº¿ng ] ) ( AND ( JOIN ( R [ diá»…n viÃªn lá»“ng tiáº¿ng ] ) [ South Park ] ) ( JOIN [ nghá» nghiá»‡p ] [ ca sÄ© ] ) ) )', '( AND ( JOIN ( R [ diá»…n viÃªn lá»“ng tiáº¿ng ] ) [ South Park ] ) ( JOIN [ nghá» nghiá»‡p ] [ ca sÄ© nháº¡c Ä‘á»“ng quÃª ] ) )']\nğŸ“Œ Truy váº¥n 2: ['( JOIN ( R [ phá»¥ lÆ°u ] ) ( JOIN ( R [ tá»a láº¡c trong hoáº·c bÃªn cáº¡nh thá»§y vá»±c ] ) [ Winnipeg ] ) )', '( JOIN ( R [ tá»a láº¡c trong hoáº·c bÃªn cáº¡nh thá»§y vá»±c ] ) ( JOIN ( R [ cá»­a sÃ´ng ] ) [ SÃ´ng Winnipeg ] ) )', '( JOIN ( R [ tá»a láº¡c trong hoáº·c bÃªn cáº¡nh thá»§y vá»±c ] ) [ Winnipeg ] ) ( JOIN ( R [ phá»¥ lÆ°u ] ) [ Winnipeg ] )', '( JOIN ( R [ tá»a láº¡c trong hoáº·c bÃªn cáº¡nh thá»§y vá»±c ] ) ( JOIN ( R [ phá»¥ lÆ°u ] ) [ SÃ´ng Winnipeg ] ) )', '( JOIN ( R [ tá»a láº¡c trong hoáº·c bÃªn cáº¡nh thá»§y vá»±c ] ) [ Winnipeg ] ) ( JOIN ( R [ phá»¥ lÆ°u ] ) [ SÃ´ng Winnipeg ] )']\nğŸ“Œ Truy váº¥n 3: ['( JOIN ( R [ ngÆ°á»i phá»‘i ngáº«u ] ) ( JOIN ( R [ diá»…n viÃªn ] ) [ Bepanaah ] ) )', '( JOIN ( R [ ngÆ°á»i phá»‘i ngáº«u ] ) ( JOIN ( R [ diá»…n viÃªn ] ) [ Bepanah ] ) )', '( JOIN ( R [ ngÆ°á»i tÃ¬nh ] ) ( JOIN ( R [ diá»…n viÃªn ] ) [ Bepanaah ] ) )', '( JOIN ( R [ ngÆ°á»i phá»‘i ngáº«u ] ) ( JOIN ( R [ diá»…n viÃªn ] ) [ BepanÄh ] ) )', '( JOIN ( R [ con cÃ¡i ] ) ( JOIN ( R [ diá»…n viÃªn ] ) [ Bepanaah ] ) )']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from tqdm import tqdm\n\noutput_data = []\n\n# âœ… Duyá»‡t qua tá»«ng cÃ¢u há»i vÃ  táº¡o truy váº¥n logic vá»›i beam search\nfor data in tqdm(json_data):\n    question = data[\"input\"]\n    predicted_query = generate_query(question)\n    output_data.append({\n        \"question\": question,\n        \"predicted_query\": predicted_query,\n        \"gen_label\": data[\"output\"]\n    })\n\n# âœ… Ghi káº¿t quáº£ vÃ o file JSON\noutput_file = \"/kaggle/working/generated_predictions_test_3ep.json\"\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    json.dump(output_data, f, indent=4, ensure_ascii=False)\n\nprint(f\"âœ… Dá»± Ä‘oÃ¡n hoÃ n táº¥t! Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:50:55.548446Z","iopub.execute_input":"2025-03-14T13:50:55.548764Z","execution_failed":"2025-03-14T13:51:26.742Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 8/4450 [00:30<4:38:37,  3.76s/it]","output_type":"stream"}],"execution_count":null}]}