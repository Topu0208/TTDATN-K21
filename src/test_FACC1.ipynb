{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simcse import SimCSE\n",
    "from entity_retrieval import surface_index_memory\n",
    "# from your_module import convert_normed_to_s_expression  # Đổi 'your_module' thành tên file của bạn\n",
    "# from simcse import SimCSE\n",
    "from itertools import product\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ujson\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:entity_retrieval.surface_index_memory:Loading entity vocabulary from disk.\n",
      "INFO:entity_retrieval.surface_index_memory:Loading surfaces from disk.\n",
      "INFO:entity_retrieval.surface_index_memory:Done initializing surface index.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "surface_index = surface_index_memory.EntitySurfaceIndexMemory(\n",
    "    \"vi_entity_list_file_wikidata_complete_all_mention\", \"vi_entity_surface_map_file_wikidata_complete_all_mention\",\"vi_wiki_complete_all_mention\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q42889', 'Q66424155', 'Q48833186', 'Q7918414', 'Q7918409', 'Q28094310', 'Q66424271']\n",
      "['P1686']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def find_wikidata_entity(label: str, language: str = \"vi\"):\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"search\": label,\n",
    "        \"language\": language,\n",
    "        \"type\": \"item\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Lỗi truy vấn Wikidata: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"search\" in data and data[\"search\"]:\n",
    "        results = [(item[\"id\"], item.get(\"label\", \"\"), item.get(\"description\", \"\")) for item in data[\"search\"]]\n",
    "\n",
    "        # Lọc bỏ các kết quả không có nhãn hợp lệ (None hoặc số)\n",
    "        results = [(id, str(label), desc) for id, label, desc in results if isinstance(label, str)]\n",
    "\n",
    "        # # Ưu tiên nhãn khớp chính xác trước\n",
    "        # results.sort(key=lambda x: (x[1].lower() != label.lower(), not x[2]), reverse=True)\n",
    "\n",
    "        exact_matches = [item[0] for item in results if item[1].lower() == label.lower()]\n",
    "        if exact_matches:\n",
    "            return exact_matches\n",
    "\n",
    "    return search_wikidata_pages(label)\n",
    "\n",
    "\n",
    "def search_wikidata_pages(label: str):\n",
    "    \"\"\"\n",
    "    Tìm các trang Wikidata có chứa thực thể liên quan đến nhãn.\n",
    "    \"\"\"\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": label,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Lỗi truy vấn trang Wikidata: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"query\" in data and \"search\" in data[\"query\"]:\n",
    "        return [f\"{item['title']}\" for item in data[\"query\"][\"search\"]]\n",
    "\n",
    "    return None\n",
    "def search_wikidata_entities(label: str, language: str = \"vi\"):\n",
    "    \"\"\"\n",
    "    Tìm các thực thể Wikidata có mã Q cụ thể liên quan đến nhãn.\n",
    "    \"\"\"\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"search\": label,\n",
    "        \"language\": language,\n",
    "        \"type\": \"item\",  # Chỉ tìm thực thể (bỏ qua quan hệ P)\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Lỗi truy vấn Wikidata: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"search\" in data:\n",
    "        return [item[\"id\"] for item in data[\"search\"]]  # Lấy mã thực thể Q\n",
    "\n",
    "    return None\n",
    "def search_wikidata_relations(label: str, language: str = \"vi\"):\n",
    "    \"\"\"\n",
    "    Tìm các mã quan hệ (P...) trên Wikidata dựa vào nhãn.\n",
    "    \"\"\"\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"search\": label,\n",
    "        \"language\": language,\n",
    "        \"type\": \"property\",  # Chỉ tìm quan hệ (P...)\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Lỗi truy vấn Wikidata: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"search\" in data:\n",
    "        return [item[\"id\"] for item in data[\"search\"]]  # Lấy mã quan hệ P\n",
    "\n",
    "    return None\n",
    "# Ví dụ tìm mã thực thể cho \"Mary Lou Retton\"\n",
    "print(search_wikidata_entities(\"vehicle\"))\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "print(search_wikidata_relations(\"cho tác phẩm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số thực thể: 422\n",
      "Tỉ lệ khớp chính xác: 98.34%\n",
      "Tỉ lệ chứa mã thực thể đúng: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def evaluate_wikidata_matching(test_file):\n",
    "    with open(test_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_data = json.load(f)\n",
    "    test_data = test_data[:250]\n",
    "    total_entities = 0\n",
    "    exact_match_count = 0\n",
    "    contained_match_count = 0\n",
    "    \n",
    "    for data in test_data:\n",
    "        gold_entity_map = data.get(\"gold_relation_map\", {})\n",
    "        for gold_id, label in gold_entity_map.items():\n",
    "\n",
    "            total_entities += 1\n",
    "            label = str(label)\n",
    "            result = search_wikidata_relations(label)[:10]\n",
    "            \n",
    "            if not result:\n",
    "                continue\n",
    "            # Kiểm tra nếu mã đầu tiên trong danh sách khớp\n",
    "            if result[0] == gold_id:\n",
    "                exact_match_count += 1\n",
    "            \n",
    "            # Kiểm tra nếu danh sách có chứa mã gold_id\n",
    "            if gold_id in result:\n",
    "                contained_match_count += 1\n",
    "    \n",
    "    exact_match_ratio = (exact_match_count / total_entities) * 100 if total_entities > 0 else 0\n",
    "    contained_match_ratio = (contained_match_count / total_entities) * 100 if total_entities > 0 else 0\n",
    "    \n",
    "    print(f\"Tổng số thực thể: {total_entities}\")\n",
    "    print(f\"Tỉ lệ khớp chính xác: {exact_match_ratio:.2f}%\")\n",
    "    print(f\"Tỉ lệ chứa mã thực thể đúng: {contained_match_ratio:.2f}%\")\n",
    "\n",
    "# Gọi hàm đánh giá với tập test\n",
    "evaluate_wikidata_matching(\"Data/LC-QuAD2.0/label_map/LC-QuAD2.0_test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TOPU\\anaconda3\\envs\\py38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Load model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Trích xuất vector embedding từ mô hình\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Mean pooling\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entity(label, label_map, facc1_index, top_k=20, similarity_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Tìm thực thể hoặc quan hệ từ gold maps, SimCSE hoặc FACC1.\n",
    "    \"\"\"\n",
    "    label_lower = label.lower()\n",
    "\n",
    "    # Nếu có trong label_map, trả về ngay\n",
    "    if label_map and label_lower in label_map:\n",
    "        return label_map[label_lower]\n",
    "\n",
    "    # Lấy embedding cho label\n",
    "    label_embedding = get_embedding(label_lower).reshape(1, -1)\n",
    "\n",
    "    if label_map:\n",
    "        label_keys = list(label_map.keys())\n",
    "        # Lấy embedding từ giá trị (tên thực thể) thay vì key\n",
    "        label_embeddings = np.array([get_embedding(label_map[k]) for k in label_keys]).squeeze(1)\n",
    "\n",
    "        # Normalize trước khi tính cosine similarity\n",
    "        label_embedding = normalize(label_embedding, axis=1)\n",
    "        label_embeddings = normalize(label_embeddings, axis=1)\n",
    "\n",
    "        # Tính cosine similarity\n",
    "        similarities = cosine_similarity(label_embedding, label_embeddings).flatten()\n",
    "\n",
    "        # Chọn thực thể gần nhất\n",
    "        merged_list = list(zip(label_keys, similarities))\n",
    "        sorted_list = sorted(merged_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_list and sorted_list[0][1] > 0.2:\n",
    "            return label_map[sorted_list[0][0]]\n",
    "        \n",
    "    facc1_cand_entities = facc1_index.get_indexrange_entity_el_pro_one_mention(label_lower, top_k=50)\n",
    "    print(facc1_cand_entities)\n",
    "    if facc1_cand_entities:\n",
    "        temp = []\n",
    "        for key in list(facc1_cand_entities.keys())[1:]:\n",
    "            if facc1_cand_entities[key] >= 0.001:\n",
    "                temp.append(key)\n",
    "        if len(temp) > 0:\n",
    "            label = [list(facc1_cand_entities.keys())[0]]+temp\n",
    "        else:\n",
    "            label = list(facc1_cand_entities.keys())[0]\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcse_model = model  # Mô hình SimCSE của bạn\n",
    "facc1_index = surface_index\n",
    "label_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Q6171615', 1.0)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Q6171615'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entity(\"Jean Umansky\", label_map,facc1_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity với Vår Frelsers gravlund (Q1069938): 0.4353713095188141\n",
      "Similarity với Henrik Ibsen (Q36661): 0.32842618227005005\n",
      "Kết quả: Vår Frelsers gravlund\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.preprocessing import normalize\n",
    "\n",
    "# # Load model & tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "# model = AutoModel.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "\n",
    "\n",
    "# def get_embedding(text):\n",
    "#     \"\"\"Trích xuất vector embedding từ mô hình\"\"\"\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     # Mean pooling\n",
    "#     embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "#     return embeddings\n",
    "\n",
    "\n",
    "# gold_entity_map = {\n",
    "#     \"Q1069938\": \"Vår Frelsers gravlund\",\n",
    "#     \"Q36661\": \"Henrik Ibsen\"\n",
    "# }\n",
    "\n",
    "# label_lower = \"Nghĩa trang Var Frelsers\".lower()  # CHUẨN HÓA\n",
    "\n",
    "# # Lấy embedding cho label\n",
    "# label_embedding = get_embedding(label_lower).reshape(1, -1)\n",
    "\n",
    "# if gold_entity_map:\n",
    "#     label_keys = list(gold_entity_map.keys())\n",
    "#     # Lấy embedding từ giá trị (tên thực thể) thay vì key\n",
    "#     label_embeddings = np.array([get_embedding(gold_entity_map[k]) for k in label_keys]).squeeze(1)\n",
    "\n",
    "#     # Normalize trước khi tính cosine similarity\n",
    "#     label_embedding = normalize(label_embedding, axis=1)\n",
    "#     label_embeddings = normalize(label_embeddings, axis=1)\n",
    "\n",
    "#     # Tính cosine similarity\n",
    "#     similarities = cosine_similarity(label_embedding, label_embeddings).flatten()\n",
    "\n",
    "#     # In giá trị cosine similarity từng thực thể\n",
    "#     for key, sim in zip(label_keys, similarities):\n",
    "#         print(f\"Similarity với {gold_entity_map[key]} ({key}): {sim}\")\n",
    "\n",
    "#     # Chọn thực thể gần nhất\n",
    "#     merged_list = list(zip(label_keys, similarities))\n",
    "#     sorted_list = sorted(merged_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     if sorted_list and sorted_list[0][1] > 0.2:\n",
    "#         print(\"Kết quả:\", gold_entity_map[sorted_list[0][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_expression(expr):\n",
    "    \"\"\"Kiểm tra tính hợp lệ của biểu thức bằng cách đếm số ngoặc mở và đóng.\"\"\"\n",
    "    count = 0\n",
    "    for char in expr:\n",
    "        if char == '(':\n",
    "            count += 1\n",
    "        elif char == ')':\n",
    "            count -= 1\n",
    "        if count < 0:\n",
    "            return False  # Gặp ngoặc đóng trước ngoặc mở\n",
    "    return count == 0\n",
    "\n",
    "def fix_unbalanced_parentheses(expr):\n",
    "    \"\"\"Loại bỏ ngoặc đóng dư nếu có.\"\"\"\n",
    "    while not is_valid_expression(expr) and expr.endswith(')'):\n",
    "        expr = expr[:-1]\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_entity_or_relation(label, label_map, simcse_model, facc1_index, top_k=50, similarity_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Tìm mã tương ứng cho thực thể hoặc quan hệ từ gold maps, SimCSE hoặc FACC1.\n",
    "    Nếu label_map rỗng, sẽ bỏ qua bước similarity và chuyển thẳng sang tra cứu FACC1.\n",
    "    \"\"\"\n",
    "    search = True\n",
    "    label_lower = label.lower()\n",
    "    # Nếu label_map không rỗng, thử tra cứu qua label_map và similarity\n",
    "    if label_map:\n",
    "        if label_lower in label_map:\n",
    "            return label_map[label_lower]\n",
    "        similarities = simcse_model.similarity([label_lower], list(label_map.keys()))\n",
    "        if list(label_map.keys()):\n",
    "            merged_list = list(zip(label_map.keys(), similarities[0]))\n",
    "            sorted_list = sorted(merged_list, key=lambda x: x[1], reverse=True)\n",
    "            if sorted_list and sorted_list[0][1] > similarity_threshold:\n",
    "                return label_map[sorted_list[0][0]]\n",
    "    \n",
    "    # Nếu không có dữ liệu từ label_map, chuyển thẳng sang tra cứu FACC1\n",
    "    try:\n",
    "        print(label)\n",
    "        facc1_candidates = facc1_index.get_indexrange_entity_el_pro_one_mention(label, top_k=top_k)\n",
    "    except Exception as e:\n",
    "        # Nếu có lỗi xảy ra trong quá trình tra cứu FACC1, log lỗi và trả về label gốc\n",
    "        print(f\"Lỗi khi truy xuất FACC1 cho label '{label}': {e}\")\n",
    "        return label\n",
    "\n",
    "    if facc1_candidates:\n",
    "        keys = list(facc1_candidates.keys())\n",
    "        if not keys:\n",
    "            return label\n",
    "        try:\n",
    "            # Lấy candidate đầu tiên và các candidate có điểm >= 0.001\n",
    "            temp = [key for key in keys[1:] if facc1_candidates[key] >= 0.001]\n",
    "            return [keys[0]] + temp if temp else keys[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xử lý kết quả FACC1 cho label '{label}': {e}\")\n",
    "            return label\n",
    "\n",
    "    return label\n",
    "\n",
    "# def invert_map(original_map):\n",
    "#     \"\"\"Đảo ngược key-value trong map để tìm mã từ tên.\"\"\"\n",
    "#     return {v.lower(): k for k, v in original_map.items()}\n",
    "\n",
    "def parse_nsexpr(expr):\n",
    "    \"\"\"\n",
    "    Chuyển chuỗi biểu thức thành cây cấu trúc dạng nested list.\n",
    "    Hàm này dùng duyệt ký tự, khi gặp '(' sẽ tìm phần con cho đến khi khớp với ')',\n",
    "    và giữ nguyên nội dung trong ngoặc vuông.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(expr):\n",
    "        if expr[i].isspace():\n",
    "            i += 1\n",
    "        elif expr[i] == '(':\n",
    "            # Tìm phần con của biểu thức trong ngoặc đơn\n",
    "            count = 1\n",
    "            j = i + 1\n",
    "            while j < len(expr) and count > 0:\n",
    "                if expr[j] == '(':\n",
    "                    count += 1\n",
    "                elif expr[j] == ')':\n",
    "                    count -= 1\n",
    "                j += 1\n",
    "            # Đệ quy phân tích phần con (loại bỏ ngoặc bao ngoài)\n",
    "            subtree = parse_nsexpr(expr[i+1:j-1])\n",
    "            tokens.append(subtree)\n",
    "            i = j\n",
    "        elif expr[i] == '[':\n",
    "            # Giữ nguyên nội dung trong ngoặc vuông\n",
    "            j = expr.find(']', i)\n",
    "            if j == -1:\n",
    "                return \"\"\n",
    "                raise ValueError(\"Không tìm thấy dấu ']' kết thúc.\")\n",
    "                \n",
    "            token = expr[i:j+1].strip()\n",
    "            tokens.append(token)\n",
    "            i = j + 1\n",
    "        else:\n",
    "            # Đọc một token cho đến khi gặp khoảng trắng hoặc ngoặc\n",
    "            j = i\n",
    "            while j < len(expr) and (not expr[j].isspace()) and expr[j] not in ['(', ')']:\n",
    "                j += 1\n",
    "            tokens.append(expr[i:j])\n",
    "            i = j\n",
    "    return tokens\n",
    "\n",
    "def collect_labels(tree):\n",
    "    \"\"\"\n",
    "    Duyệt cây cấu trúc (nested list) để thu thập các nhãn của quan hệ và thực thể.\n",
    "    Giả sử:\n",
    "      - Biểu thức JOIN có dạng: [\"JOIN\", relation_part, entity_part]\n",
    "      - Phần relation_part: nếu là list và bắt đầu bằng \"R\", thì phần thứ hai chứa nhãn quan hệ (dạng \"[ label ]\"). \n",
    "        Nếu là chuỗi dạng \"[ label ]\" thì đó cũng là nhãn quan hệ.\n",
    "      - Phần entity_part: nếu là chuỗi dạng \"[ label ]\" thì đó là nhãn thực thể, nếu là list thì xử lý đệ quy.\n",
    "      - Biểu thức AND sẽ có nhiều biểu thức con.\n",
    "    \"\"\"\n",
    "    relations = []\n",
    "    entities = []\n",
    "    \n",
    "    if isinstance(tree, list) and tree:\n",
    "        # Nếu token đầu tiên là JOIN hoặc AND\n",
    "        op = tree[0]\n",
    "        if isinstance(op, str):\n",
    "            op_upper = op.upper()\n",
    "        else:\n",
    "            op_upper = \"\"\n",
    "        \n",
    "        if op_upper == \"JOIN\":\n",
    "            # Xử lý phần quan hệ\n",
    "            if len(tree) >= 2:\n",
    "                rel_part = tree[1]\n",
    "                # Nếu là list dạng [ \"R\", \"[ label ]\" ]\n",
    "                if isinstance(rel_part, list) and len(rel_part) >= 2 and isinstance(rel_part[0], str) and rel_part[0].upper() == \"R\":\n",
    "                    token = rel_part[1]\n",
    "                    if isinstance(token, str) and token.startswith('[') and token.endswith(']'):\n",
    "                        rel_label = token[1:-1].strip()\n",
    "                        relations.append(rel_label)\n",
    "                # Nếu là chuỗi dạng \"[ label ]\"\n",
    "                elif isinstance(rel_part, str) and rel_part.startswith('[') and rel_part.endswith(']'):\n",
    "                    rel_label = rel_part[1:-1].strip()\n",
    "                    relations.append(rel_label)\n",
    "                else:\n",
    "                    # Nếu không đúng định dạng, duyệt đệ quy\n",
    "                    sub_rel, sub_ent = collect_labels(rel_part)\n",
    "                    relations.extend(sub_rel)\n",
    "                    entities.extend(sub_ent)\n",
    "            # Xử lý phần thực thể\n",
    "            if len(tree) >= 3:\n",
    "                ent_part = tree[2]\n",
    "                if isinstance(ent_part, list):\n",
    "                    sub_rel, sub_ent = collect_labels(ent_part)\n",
    "                    relations.extend(sub_rel)\n",
    "                    entities.extend(sub_ent)\n",
    "                elif isinstance(ent_part, str) and ent_part.startswith('[') and ent_part.endswith(']'):\n",
    "                    ent_label = ent_part[1:-1].strip()\n",
    "                    entities.append(ent_label)\n",
    "        elif op_upper == \"AND\":\n",
    "            # Với AND, duyệt tất cả các phần con\n",
    "            for sub in tree[1:]:\n",
    "                sub_rel, sub_ent = collect_labels(sub)\n",
    "                relations.extend(sub_rel)\n",
    "                entities.extend(sub_ent)\n",
    "        else:\n",
    "            # Nếu không phải JOIN hay AND, duyệt tất cả các phần tử nếu chúng là list\n",
    "            for elem in tree:\n",
    "                if isinstance(elem, list):\n",
    "                    sub_rel, sub_ent = collect_labels(elem)\n",
    "                    relations.extend(sub_rel)\n",
    "                    entities.extend(sub_ent)\n",
    "    return relations, entities\n",
    "\n",
    "\n",
    "\n",
    "def extract_entities_and_relations(normed_expr):\n",
    "\n",
    "    if not normed_expr or len(normed_expr) == 0:  # Kiểm tra nếu normed_expr rỗng\n",
    "        return [], []\n",
    "    \n",
    "    if normed_expr[0] != \"(\":\n",
    "        return [], []\n",
    "    \n",
    "    tree = parse_nsexpr(normed_expr)\n",
    "    if tree is None:\n",
    "        return [], []  # Trả về danh sách rỗng nếu parse thất bại\n",
    "    \n",
    "    return collect_labels(tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_normed_to_s_expression(normed_expr, gold_relation_map, gold_entity_map, simcse_model, facc1_index):\n",
    "    \"\"\"\n",
    "    Chuyển đổi từ normed_sexpression sang s_expression.\n",
    "    Sau khi trích xuất các nhãn quan hệ và thực thể từ normed_expr,\n",
    "    ta lấy danh sách các mã ứng viên cho mỗi nhãn và tạo hoán vị giữa các cặp ứng viên đó.\n",
    "    Kết quả trả về là một danh sách các s_expression khả dĩ.\n",
    "    \"\"\"\n",
    "    # Đảo ngược map để lấy mã từ tên\n",
    "    # inverted_relation_map = invert_map(gold_relation_map)\n",
    "    # inverted_entity_map = invert_map(gold_entity_map)\n",
    "    normed_expr = fix_unbalanced_parentheses(normed_expr)\n",
    "    # Trích xuất các nhãn quan hệ và thực thể từ biểu thức\n",
    "    relations, entities = extract_entities_and_relations(normed_expr)\n",
    "    \n",
    "    # Tạo mapping từ token xuất hiện trong biểu thức sang danh sách các ứng viên mã.\n",
    "    # Ví dụ: token_str = \"[ author ]\"\n",
    "    candidate_map = {}\n",
    "    \n",
    "    for rel in relations:\n",
    "        token = f'[ {rel} ]'\n",
    "        candidate = find_entity_or_relation(rel, gold_relation_map, simcse_model, facc1_index)\n",
    "        # Nếu candidate không phải danh sách, chuyển nó thành danh sách để tạo hoán vị\n",
    "        if not isinstance(candidate, list):\n",
    "            candidate = [candidate]\n",
    "        candidate_map[token] = candidate\n",
    "        \n",
    "    for ent in entities:\n",
    "        token = f'[ {ent} ]'\n",
    "        candidate = find_entity_or_relation(ent, gold_entity_map, simcse_model, facc1_index)\n",
    "        if not isinstance(candidate, list):\n",
    "            candidate = [candidate]\n",
    "        candidate_map[token] = candidate\n",
    "    \n",
    "    # Nếu không có token nào cần thay thế, trả về biểu thức gốc\n",
    "    if not candidate_map:\n",
    "        return [normed_expr]\n",
    "    \n",
    "    # Lấy danh sách các token và danh sách các danh sách ứng viên tương ứng\n",
    "    tokens = list(candidate_map.keys())\n",
    "    candidate_lists = [candidate_map[token] for token in tokens]\n",
    "    \n",
    "    # Tạo tất cả các hoán vị ứng viên (Cartesian product)\n",
    "    all_combinations = list(product(*candidate_lists))\n",
    "    \n",
    "    s_expressions = []\n",
    "    for comb in all_combinations:\n",
    "        temp_expr = normed_expr\n",
    "        # Với mỗi token, thay thế bằng ứng viên tương ứng theo hoán vị\n",
    "        for token, replacement in zip(tokens, comb):\n",
    "            temp_expr = temp_expr.replace(token, replacement)\n",
    "        s_expressions.append(temp_expr)\n",
    "    \n",
    "    return s_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SExpressionParser:\n",
    "    def __init__(self):\n",
    "        self.var_counter = 1  # Đếm số biến trung gian (?X1, ?X2, ...)\n",
    "\n",
    "    def get_new_var(self):\n",
    "        \"\"\"Tạo biến trung gian mới.\"\"\"\n",
    "        var_name = f\"?X{self.var_counter}\"\n",
    "        self.var_counter += 1\n",
    "        return var_name\n",
    "\n",
    "    def parse_s_expr(self, s_expr):\n",
    "        \"\"\"Chuyển đổi S-Expression thành danh sách lồng nhau.\"\"\"\n",
    "        s_expr = re.sub(r'\\(', ' ( ', s_expr)\n",
    "        s_expr = re.sub(r'\\)', ' ) ', s_expr)\n",
    "        tokens = s_expr.split()\n",
    "        return self.build_tree(tokens)\n",
    "\n",
    "    def build_tree(self, tokens):\n",
    "        \"\"\"Chuyển đổi danh sách token thành cây lồng nhau.\"\"\"\n",
    "        if not tokens:\n",
    "            return None\n",
    "        token = tokens.pop(0)\n",
    "        if token == \"(\":\n",
    "            sub_expr = []\n",
    "            while tokens[0] != \")\":\n",
    "                sub_expr.append(self.build_tree(tokens))\n",
    "            tokens.pop(0)  # Bỏ dấu \")\"\n",
    "            return sub_expr\n",
    "        elif token == \")\":\n",
    "            raise ValueError(\"Unexpected ')'\")\n",
    "        else:\n",
    "            return token\n",
    "\n",
    "    def process_join(self, expr, target_var):\n",
    "        \"\"\"\n",
    "        Xử lý JOIN, tạo triple SPARQL.\n",
    "        \"\"\"\n",
    "        triples = []\n",
    "        if not isinstance(expr, list):\n",
    "            return expr, triples\n",
    "\n",
    "        if expr[0] == \"AND\":\n",
    "            # Xử lý từng JOIN trong AND riêng lẻ\n",
    "            for sub_expr in expr[1:]:\n",
    "                _, sub_triples = self.process_join(sub_expr, target_var)\n",
    "                triples.extend(sub_triples)\n",
    "            return target_var, triples\n",
    "\n",
    "        if expr[0] == \"JOIN\":\n",
    "            right_expr = expr[2]\n",
    "            right_triples = []\n",
    "            if isinstance(right_expr, list) and right_expr[0] == \"JOIN\":\n",
    "                right_var, right_triples = self.process_join(right_expr, self.get_new_var())\n",
    "            else: \n",
    "                right_var = right_expr\n",
    "            \n",
    "            # Xử lý nhánh trái\n",
    "            left_expr = expr[1]\n",
    "            if isinstance(left_expr, list) and left_expr[0] == \"R\":\n",
    "                rel = left_expr[1]\n",
    "                right = right_var\n",
    "                left = target_var\n",
    "                if right[0] != '?':\n",
    "                    right = \"wd:\" + right\n",
    "                if left[0] !='?':\n",
    "                    left = \"wd:\" + left   \n",
    "                triples.append([right, f\"wdt:{rel}\", left])\n",
    "            else:\n",
    "                right = right_var\n",
    "                left = target_var\n",
    "                if right[0] != '?':\n",
    "                    right = \"wd:\" + right\n",
    "                if left[0] !='?':\n",
    "                    left = \"wd:\" + left   \n",
    "                triples.append([left, f\"wdt:{left_expr}\", right])\n",
    "\n",
    "            # Thêm các triples từ nhánh phải trước khi thêm triple chính\n",
    "            triples = right_triples + triples\n",
    "            return target_var, triples\n",
    "\n",
    "        return expr, triples\n",
    "\n",
    "    def s_expr_to_sparql(self, s_expr):\n",
    "        \"\"\"Chuyển đổi từ S-Expression sang SPARQL.\"\"\"\n",
    "        parsed_expr = self.parse_s_expr(s_expr)\n",
    "        target_var = \"?answer\"\n",
    "        final_var, triples = self.process_join(parsed_expr, target_var)\n",
    "\n",
    "        sparql_body = \"\\n  \".join([\" \".join(t) + \" .\" for t in triples])\n",
    "        sparql_query = f\"\"\"PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "SELECT DISTINCT {target_var} WHERE {{ \n",
    "  {sparql_body}\n",
    "}}\"\"\"\n",
    "        return sparql_query\n",
    "\n",
    "\n",
    "def execute_query_with_odbc(sparql_query):\n",
    "    \"\"\"\n",
    "    Thực thi truy vấn SPARQL trên Wikidata endpoint và trả về kết quả.\n",
    "    \"\"\"\n",
    "    ENDPOINT_URL = \"https://query.wikidata.org/sparql\"\n",
    "    if sparql_query == None or sparql_query == []:\n",
    "        return []\n",
    "    sparql = SPARQLWrapper(ENDPOINT_URL)\n",
    "    sparql.setQuery(str(sparql_query))  # Ép kiểu về str cho chắc chắn\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    try:\n",
    "        response = sparql.query().convert()\n",
    "        answers = [item[\"answer\"][\"value\"] for item in response[\"results\"][\"bindings\"] if \"answer\" in item]\n",
    "        return answers\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Đọc file JSONL và trả về danh sách các object\"\"\"\n",
    "\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read().replace('(EXPECTED RESULT)', 'null').replace('(QUESTION)', 'null')\n",
    "\n",
    "    try:\n",
    "        data = ujson.loads(content)\n",
    "        print(\"JSON loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON loaded successfully!\n",
      "JSON loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "predictions = load_jsonl(\"LLMs/beam_prediction/generated_predictions_beam.json\")\n",
    "gold_data = load_jsonl(\"Data/LC-QuAD2.0/label_map/LC-QuAD2.0_test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcse_model = model  # Mô hình SimCSE của bạn\n",
    "facc1_index = surface_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_entity_map = {}\n",
    "gold_relation_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"( AND ( JOIN [ occupation ] [ singer ] ) ( JOIN ( R [ voice actor ] ) [ South Park ] ) )\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupation\n",
      "voice actor\n",
      "singer\n",
      "South Park\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['( AND ( JOIN occupation singer ) ( JOIN ( R voice actor ) Q16538 ) )']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_query = convert_normed_to_s_expression(query, gold_relation_map, gold_entity_map, simcse_model, facc1_index)\n",
    "set_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
